{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Portfolio Optimization using cvxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install cvxpy and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.1.5)\n",
      "Requirement already satisfied: cvxpy==1.0.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.0.3)\n",
      "Requirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: numpy==1.14.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.14.5)\n",
      "Requirement already satisfied: pandas==0.21.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.21.1)\n",
      "Requirement already satisfied: plotly==2.2.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2017.3)\n",
      "Requirement already satisfied: requests==2.18.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.18.4)\n",
      "Requirement already satisfied: scipy==1.0.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.11.0)\n",
      "Requirement already satisfied: tqdm==4.19.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (4.19.5)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (0.70.11.1)\n",
      "Requirement already satisfied: ecos>=2 in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (2.0.7.post1)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (0.8.2)\n",
      "Requirement already satisfied: fastcache in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: osqp in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (0.6.2.post0)\n",
      "Requirement already satisfied: scs>=1.1.3 in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2019.11.28)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/lib/python3.6/site-packages (from multiprocess->cvxpy==1.0.3->-r requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: qdldl in /opt/conda/lib/python3.6/site-packages (from osqp->cvxpy==1.0.3->-r requirements.txt (line 2)) (0.1.5.post0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.3.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import quiz_tests_advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's our objective?\n",
    "http://www.cvxpy.org/\n",
    "\n",
    "Let's see how we can use optimization to meet a more advanced objective.  We want to both minimize the portfolio variance and also want to closely track a market cap weighted index.  In other words, we're trying to minimize the distance between the weights of our portfolio and the weights of the index.\n",
    "\n",
    "$Minimize \\left [ \\sigma^2_p + \\lambda \\sqrt{\\sum_{1}^{m}(weight_i - indexWeight_i)^2} \\right  ]$ where $m$ is the number of stocks in the portfolio, and $\\lambda$ is a scaling factor that you can choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "### x vector\n",
    "To create a vector of M variables $\\mathbf{x} = \\begin{bmatrix}\n",
    "x_1 &...& x_M\n",
    "\\end{bmatrix}\n",
    "$\n",
    "we can use `cvx.Variable(m)`\n",
    "\n",
    "### covariance matrix\n",
    "If we have $m$ stock series, the covariance matrix is an $m \\times m$ matrix containing the covariance between each pair of stocks.  We can use [numpy.cov](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html) to get the covariance.  We give it a 2D array in which each row is a stock series, and each column is an observation at the same period of time.\n",
    "\n",
    "The covariance matrix $\\mathbf{P} = \n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_{1,1} & ... & \\sigma^2_{1,m} \\\\ \n",
    "... & ... & ...\\\\\n",
    "\\sigma_{m,1} & ... & \\sigma^2_{m,m}  \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portfolio variance\n",
    "We can write the portfolio variance $\\sigma^2_p = \\mathbf{x^T} \\mathbf{P} \\mathbf{x}$\n",
    "\n",
    "Recall that the $\\mathbf{x^T} \\mathbf{P} \\mathbf{x}$ is called the quadratic form.\n",
    "We can use the cvxpy function `quad_form(x,P)` to get the quadratic form.\n",
    "\n",
    "### Distance from index weights\n",
    "We want portfolio weights that track the index closely.  So we want to minimize the distance between them.\n",
    "Recall from the Pythagorean theorem that you can get the distance between two points in an x,y plane by adding the square of the x and y distances and taking the square root.  Extending this to any number of dimensions is called the L2 norm.  So: $\\sqrt{\\sum_{1}^{n}(weight_i - indexWeight_i)^2}$  Can also be written as $\\left \\| \\mathbf{x} - \\mathbf{index} \\right \\|_2$.  There's a cvxpy function called [norm()](https://www.cvxpy.org/api_reference/cvxpy.atoms.other_atoms.html#norm)\n",
    "`norm(x, p=2, axis=None)`.  The default is already set to find an L2 norm, so you would pass in one argument, which is the difference between your portfolio weights and the index weights.\n",
    "\n",
    "### objective function\n",
    "We want to minimize both the portfolio variance and the distance of the portfolio weights from the index weights.\n",
    "We also want to choose a `scale` constant, which is $\\lambda$ in the expression. This lets us choose how much priority we give to minimizing the difference from the index, relative to minimizing the variance of the portfolio.  If you choose a higher value for `scale` ($\\lambda$), do you think this gives more priority to minimizing the difference, or minimizing the variance?\n",
    "\n",
    "We can find the objective function using cvxpy `objective = cvx.Minimize()`.  Can you guess what to pass into this function?\n",
    "\n",
    "### constraints\n",
    "We can also define our constraints in a list.  For example, you'd want the weights to sum to one. So $\\sum_{1}^{n}x = 1$.  You may also need to go long only, which means no shorting, so no negative weights.  So $x_i >0 $ for all $i$. you could save a variable as `[x >= 0, sum(x) == 1]`, where x was created using `cvx.Variable()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization\n",
    "So now that we have our objective function and constraints, we can solve for the values of $\\mathbf{x}$.\n",
    "cvxpy has the constructor `Problem(objective, constraints)`, which returns a `Problem` object.\n",
    "\n",
    "The `Problem` object has a function solve(), which returns the minimum of the solution.  In this case, this is the minimum variance of the portfolio.\n",
    "\n",
    "It also updates the vector $\\mathbf{x}$.\n",
    "\n",
    "We can check out the values of $x_A$ and $x_B$ that gave the minimum portfolio variance by using `x.value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Wrong value for optimize_portfolio.\n\nINPUT returns:\n[[-0.11883111 -0.1469463   0.63755403 -0.21006425  0.49668876  0.20373633\n   0.10927073  0.51115583 -0.30443551 -0.2341129   0.04581379 -0.01496711\n   0.16869946 -0.07285331  0.14188842 -0.11479131 -0.46175213 -0.1211042\n   0.08858875 -0.1791084   0.31475378  0.06816197  0.3535345   0.23006535\n   0.58459466  0.63444655 -0.32928495  0.61527269  0.95647319  0.26943801\n  -0.04238255  0.25981564  0.26999509  0.33246046 -0.21662003 -0.20875772\n  -0.30682819  0.01038926 -0.33958063  0.08191203 -0.11053112  0.17009728\n   0.36088821 -0.19612466 -0.27049884 -0.02796433 -0.50986419  0.45429385\n   0.10479335  0.50421112 -0.06651771  0.23235973 -0.01160832  0.1918223\n   0.21664661 -0.02297771 -0.47191185 -0.02743824 -0.46749222  0.17966951\n  -0.14368577 -0.22070003 -0.31553223  0.12655371  0.49253625 -0.33704681\n   0.26513199 -0.04478558 -0.64217305  0.25787403 -0.23964023  0.07030887\n  -0.34983839  0.10536952 -0.32852291  0.01654811  0.04293219 -0.34609811\n   0.00217641 -0.20317891  0.22401243  0.05551018 -0.18243244  0.12430752\n   0.28927258  0.12773519 -0.06256805  0.25090297  0.38651433  0.3184296\n   0.00386155  0.28961471  0.04469353 -0.16849178 -0.28511773  0.20820354\n   0.10932314  0.11873305 -0.08570684 -0.11188672  0.28101147  0.11925543\n   0.31964461  0.12961372  0.25315347  0.00587285  0.19553422  0.13218578\n  -0.0122543   0.04292971 -0.15000483  0.33013272 -0.34712286 -0.26056358\n   0.02574949 -0.28684727  0.45440637 -0.09032618  0.10873096  0.01544762\n   0.2890028   0.50864679  0.10974689  0.42642412  0.10760943 -0.45488927\n   0.13267658 -0.10491736 -0.13700061 -0.66691509 -0.21976182  0.28620365\n  -0.12860238  0.06095307  0.43035635 -0.18205305 -0.11059684 -0.24391303\n   0.25720039  0.02286026  0.38297195  0.18941348  0.67505277  0.28790141\n  -0.13617345 -0.08570451  0.07484422  0.05427303 -0.35961979 -0.12141576\n  -0.43196368  0.46082543 -0.08436735  0.32561713 -0.12173825  0.06935498\n   0.11787802  0.07685019  0.25763774  0.03232812 -0.16166615 -0.27537979\n   0.01875251  0.09768058 -0.06873866  0.45293381 -0.10298101  0.36566678\n  -0.20346577  0.11852888  0.47121835  0.10905427 -0.45459969  0.43635296\n  -0.02661846 -0.21706719  0.06210583  0.16012797  0.24402433 -0.15065739\n  -0.11813231  0.37528819  0.39785959  0.25453137 -0.33516201 -0.34536812\n   0.16372705 -0.25393434 -0.18243037  0.23095165  0.27600567 -0.21151916\n   0.26046452  0.19457497  0.28848936  0.60513173 -0.25957702 -0.11981384\n  -0.27853013 -0.45792024  0.40689822  0.27995875  0.25069937  0.04768508\n  -0.38304332  0.49744278 -0.07629105 -0.5057488   0.24459147  0.36278363\n   0.24936466 -0.5485097   0.06235044  0.30790032  0.20838185 -0.24153112\n  -0.05779408 -0.14414512  0.13638005  0.03370995 -0.15155199 -0.1733269\n  -0.17080953  0.54106308  0.63949208  0.30871532  0.2627204   0.56338457\n  -0.08323434  0.2237056   0.26433978  0.49642774  0.03416162  0.48716541\n  -0.17338401 -0.12165461 -0.23700284 -0.18271879  0.02031622  0.3956831\n  -0.03263555 -0.5849339   0.25921119  0.44089722 -0.18430086  0.16289145\n   0.17995169  0.35111187  0.05617853 -0.12621005  0.52631563 -0.1677763 ]\n [-0.11883216 -0.14694723  0.63755315 -0.21006352  0.49668693  0.20373625\n   0.10927036  0.51115591 -0.30443435 -0.23411166  0.04581487 -0.01496631\n   0.16869852 -0.07285343  0.14188781 -0.11479029 -0.46175334 -0.12110422\n   0.08859004 -0.17910925  0.31475314  0.06816057  0.35353527  0.23006464\n   0.58459498  0.634445   -0.32928372  0.61527284  0.95647247  0.26943765\n  -0.04238129  0.25981583  0.26999426  0.3324605  -0.21661979 -0.20875785\n  -0.30682783  0.01039033 -0.33958132  0.08191336 -0.11053227  0.17009588\n   0.3608885  -0.19612518 -0.27049883 -0.0279644  -0.50986534  0.45429397\n   0.10479333  0.50421253 -0.06651908  0.23235984 -0.01160766  0.19182359\n   0.21664493 -0.02297803 -0.47191334 -0.02743829 -0.46749247  0.17966774\n  -0.14368533 -0.22070084 -0.31553195  0.12655265  0.49253567 -0.33704514\n   0.2651332  -0.04478692 -0.6421731   0.25787408 -0.23964032  0.07030827\n  -0.34983737  0.10537003 -0.32852215  0.01654786  0.04293211 -0.34609849\n   0.00217689 -0.20317861  0.22401146  0.05551032 -0.18243207  0.12430855\n   0.28927177  0.12773452 -0.06256725  0.2509034   0.38651412  0.31842819\n   0.00386069  0.28961497  0.04469224 -0.1684903  -0.28511967  0.2082034\n   0.10932323  0.11873427 -0.08570699 -0.11188763  0.28101179  0.11925427\n   0.31964398  0.12961355  0.25315342  0.00587253  0.19553578  0.13218485\n  -0.01225431  0.04292897 -0.15000506  0.3301319  -0.34712304 -0.26056413\n   0.02574821 -0.28684763  0.45440465 -0.09032739  0.10873176  0.01544722\n   0.28900267  0.50864726  0.10974705  0.42642457  0.10760907 -0.45489075\n   0.1326754  -0.10491738 -0.13700149 -0.66691436 -0.2197632   0.28620333\n  -0.12860224  0.0609521   0.43035657 -0.18205235 -0.11059838 -0.24391375\n   0.25720128  0.0228605   0.38297156  0.18941286  0.67505233  0.28790026\n  -0.13617276 -0.085705    0.07484249  0.05427266 -0.35962129 -0.12141543\n  -0.43196374  0.46082506 -0.08436694  0.32561657 -0.12173894  0.06935532\n   0.1178788   0.07685079  0.25763738  0.0323275  -0.16166591 -0.27537948\n   0.01875225  0.0976798  -0.06873886  0.45293378 -0.10298198  0.36566639\n  -0.20346727  0.11853031  0.47121694  0.10905323 -0.45459953  0.43635338\n  -0.02661874 -0.2170683   0.06210578  0.16012664  0.2440237  -0.15065752\n  -0.11813315  0.37528888  0.39786082  0.25453152 -0.33516294 -0.3453673\n   0.16372683 -0.25393303 -0.18243154  0.23095003  0.27600715 -0.21151953\n   0.26046459  0.19457453  0.28848904  0.60513181 -0.25957815 -0.11981527\n  -0.27853005 -0.45792075  0.40689782  0.27995852  0.25069941  0.04768465\n  -0.38304236  0.49744457 -0.07629085 -0.50574794  0.24459319  0.36278209\n   0.24936433 -0.54850952  0.06234996  0.30790058  0.20838137 -0.24153266\n  -0.05779423 -0.14414401  0.13637944  0.03370988 -0.15155226 -0.173328\n  -0.17081092  0.54106444  0.6394923   0.30871512  0.26272086  0.56338477\n  -0.08323501  0.22370561  0.26433901  0.49642718  0.03416087  0.48716492\n  -0.1733855  -0.12165455 -0.23700188 -0.18271812  0.02031637  0.39568266\n  -0.03263674 -0.58493558  0.25921003  0.44089831 -0.18430052  0.16289136\n   0.17995125  0.35111083  0.05617799 -0.12620927  0.52631706 -0.16777615]\n [-0.11883062 -0.14694583  0.63755242 -0.21006357  0.49668737  0.20373551\n   0.10927123  0.51115569 -0.30443401 -0.23411205  0.04581446 -0.01496578\n   0.16869901 -0.07285297  0.14188947 -0.11479034 -0.46175323 -0.12110448\n   0.08859013 -0.17910866  0.31475348  0.06816246  0.35353549  0.23006489\n   0.58459504  0.63444472 -0.32928364  0.61527252  0.95647254  0.26943741\n  -0.0423819   0.25981658  0.26999494  0.33245986 -0.21662051 -0.2087583\n  -0.30682759  0.01038855 -0.33958016  0.08191255 -0.11053107  0.17009764\n   0.36088917 -0.19612482 -0.27049829 -0.02796468 -0.50986383  0.4542945\n   0.10479346  0.50421208 -0.06651837  0.23236095 -0.01160919  0.19182245\n   0.21664669 -0.0229772  -0.47191179 -0.02743865 -0.46749255  0.17966928\n  -0.14368448 -0.22070164 -0.31553285  0.12655405  0.49253485 -0.33704509\n   0.26513125 -0.04478522 -0.64217164  0.25787389 -0.23964091  0.07030763\n  -0.34983804  0.10536967 -0.32852229  0.01654943  0.04293244 -0.34609748\n   0.00217641 -0.20317787  0.22401237  0.05551014 -0.18243163  0.12430756\n   0.2892731   0.12773396 -0.06256634  0.25090252  0.38651527  0.31842956\n   0.00386112  0.28961439  0.04469231 -0.16849105 -0.28511915  0.20820455\n   0.10932289  0.11873257 -0.08570641 -0.1118865   0.28101148  0.11925551\n   0.3196439   0.12961351  0.25315363  0.00587388  0.19553563  0.13218408\n  -0.01225244  0.04292975 -0.15000394  0.33013212 -0.34712181 -0.2605626\n   0.02574983 -0.28684678  0.45440503 -0.09032669  0.10873196  0.01544702\n   0.28900326  0.50864701  0.10974679  0.42642403  0.1076095  -0.45489052\n   0.1326756  -0.10491682 -0.1370021  -0.66691417 -0.2197628   0.2862025\n  -0.12860239  0.06095268  0.43035691 -0.18205279 -0.11059688 -0.24391238\n   0.25720049  0.02285983  0.38297145  0.18941342  0.67505227  0.28790163\n  -0.13617353 -0.08570526  0.07484272  0.05427276 -0.35962133 -0.12141586\n  -0.4319635   0.46082469 -0.08436813  0.32561723 -0.12173821  0.06935447\n   0.11787848  0.07685021  0.25763796  0.03232907 -0.16166604 -0.27537894\n   0.01875115  0.09768016 -0.06873829  0.45293404 -0.10298177  0.36566587\n  -0.20346547  0.11852929  0.4712172   0.109054   -0.45459955  0.43635327\n  -0.02661813 -0.21706784  0.06210662  0.16012839  0.24402255 -0.1506581\n  -0.11813262  0.37528877  0.3978608   0.25453136 -0.33516263 -0.34536646\n   0.1637264  -0.25393337 -0.18243204  0.23095161  0.27600677 -0.21151973\n   0.2604644   0.19457589  0.28848954  0.60513246 -0.259577   -0.1198144\n  -0.27853006 -0.45791887  0.40689751  0.27995763  0.25069916  0.04768403\n  -0.38304288  0.49744339 -0.07629074 -0.50574836  0.24459192  0.36278261\n   0.24936319 -0.54851078  0.06235102  0.30789968  0.20838257 -0.24153214\n  -0.05779362 -0.14414406  0.13637859  0.03371133 -0.15155349 -0.17332805\n  -0.17081055  0.54106374  0.63949192  0.30871488  0.26272071  0.56338493\n  -0.08323554  0.22370599  0.2643387   0.49642847  0.03416028  0.48716403\n  -0.17338549 -0.12165526 -0.23700155 -0.18271778  0.02031679  0.39568173\n  -0.03263605 -0.58493552  0.25921028  0.44089783 -0.18429983  0.16289017\n   0.17995123  0.35111115  0.05617802 -0.12621002  0.52631687 -0.1677765 ]]\n\nINPUT index_weights:\n[0.9  0.15 0.05]\n\nINPUT scale:\n1e-05\n\nOUTPUT x_values:\n[0.86692136 0.11669268 0.01638596]\n\nEXPECTED OUTPUT FOR x_values:\n[0.86731656 0.11624638 0.01643706]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-de2e0e3b4a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mquiz_tests_advanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_optimize_portfolio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_portfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/workspace/tests.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproject_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tests Passed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/quiz_tests_advanced.py\u001b[0m in \u001b[0;36mtest_optimize_portfolio\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     43\u001b[0m         ])\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0massert_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_correct_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/workspace/tests.py\u001b[0m in \u001b[0;36massert_output\u001b[0;34m(fn, fn_inputs, fn_expected_outputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mout_is_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_is_close\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mout_is_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Wrong value for optimize_portfolio.\n\nINPUT returns:\n[[-0.11883111 -0.1469463   0.63755403 -0.21006425  0.49668876  0.20373633\n   0.10927073  0.51115583 -0.30443551 -0.2341129   0.04581379 -0.01496711\n   0.16869946 -0.07285331  0.14188842 -0.11479131 -0.46175213 -0.1211042\n   0.08858875 -0.1791084   0.31475378  0.06816197  0.3535345   0.23006535\n   0.58459466  0.63444655 -0.32928495  0.61527269  0.95647319  0.26943801\n  -0.04238255  0.25981564  0.26999509  0.33246046 -0.21662003 -0.20875772\n  -0.30682819  0.01038926 -0.33958063  0.08191203 -0.11053112  0.17009728\n   0.36088821 -0.19612466 -0.27049884 -0.02796433 -0.50986419  0.45429385\n   0.10479335  0.50421112 -0.06651771  0.23235973 -0.01160832  0.1918223\n   0.21664661 -0.02297771 -0.47191185 -0.02743824 -0.46749222  0.17966951\n  -0.14368577 -0.22070003 -0.31553223  0.12655371  0.49253625 -0.33704681\n   0.26513199 -0.04478558 -0.64217305  0.25787403 -0.23964023  0.07030887\n  -0.34983839  0.10536952 -0.32852291  0.01654811  0.04293219 -0.34609811\n   0.00217641 -0.20317891  0.22401243  0.05551018 -0.18243244  0.12430752\n   0.28927258  0.12773519 -0.06256805  0.25090297  0.38651433  0.3184296\n   0.00386155  0.28961471  0.04469353 -0.16849178 -0.28511773  0.20820354\n   0.10932314  0.11873305 -0.08570684 -0.11188672  0.28101147  0.11925543\n   0.31964461  0.12961372  0.25315347  0.00587285  0.19553422  0.13218578\n  -0.0122543   0.04292971 -0.15000483  0.33013272 -0.34712286 -0.26056358\n   0.02574949 -0.28684727  0.45440637 -0.09032618  0.10873096  0.01544762\n   0.2890028   0.50864679  0.10974689  0.42642412  0.10760943 -0.45488927\n   0.13267658 -0.10491736 -0.13700061 -0.66691509 -0.21976182  0.28620365\n  -0.12860238  0.06095307  0.43035635 -0.18205305 -0.11059684 -0.24391303\n   0.25720039  0.02286026  0.38297195  0.18941348  0.67505277  0.28790141\n  -0.13617345 -0.08570451  0.07484422  0.05427303 -0.35961979 -0.12141576\n  -0.43196368  0.46082543 -0.08436735  0.32561713 -0.12173825  0.06935498\n   0.11787802  0.07685019  0.25763774  0.03232812 -0.16166615 -0.27537979\n   0.01875251  0.09768058 -0.06873866  0.45293381 -0.10298101  0.36566678\n  -0.20346577  0.11852888  0.47121835  0.10905427 -0.45459969  0.43635296\n  -0.02661846 -0.21706719  0.06210583  0.16012797  0.24402433 -0.15065739\n  -0.11813231  0.37528819  0.39785959  0.25453137 -0.33516201 -0.34536812\n   0.16372705 -0.25393434 -0.18243037  0.23095165  0.27600567 -0.21151916\n   0.26046452  0.19457497  0.28848936  0.60513173 -0.25957702 -0.11981384\n  -0.27853013 -0.45792024  0.40689822  0.27995875  0.25069937  0.04768508\n  -0.38304332  0.49744278 -0.07629105 -0.5057488   0.24459147  0.36278363\n   0.24936466 -0.5485097   0.06235044  0.30790032  0.20838185 -0.24153112\n  -0.05779408 -0.14414512  0.13638005  0.03370995 -0.15155199 -0.1733269\n  -0.17080953  0.54106308  0.63949208  0.30871532  0.2627204   0.56338457\n  -0.08323434  0.2237056   0.26433978  0.49642774  0.03416162  0.48716541\n  -0.17338401 -0.12165461 -0.23700284 -0.18271879  0.02031622  0.3956831\n  -0.03263555 -0.5849339   0.25921119  0.44089722 -0.18430086  0.16289145\n   0.17995169  0.35111187  0.05617853 -0.12621005  0.52631563 -0.1677763 ]\n [-0.11883216 -0.14694723  0.63755315 -0.21006352  0.49668693  0.20373625\n   0.10927036  0.51115591 -0.30443435 -0.23411166  0.04581487 -0.01496631\n   0.16869852 -0.07285343  0.14188781 -0.11479029 -0.46175334 -0.12110422\n   0.08859004 -0.17910925  0.31475314  0.06816057  0.35353527  0.23006464\n   0.58459498  0.634445   -0.32928372  0.61527284  0.95647247  0.26943765\n  -0.04238129  0.25981583  0.26999426  0.3324605  -0.21661979 -0.20875785\n  -0.30682783  0.01039033 -0.33958132  0.08191336 -0.11053227  0.17009588\n   0.3608885  -0.19612518 -0.27049883 -0.0279644  -0.50986534  0.45429397\n   0.10479333  0.50421253 -0.06651908  0.23235984 -0.01160766  0.19182359\n   0.21664493 -0.02297803 -0.47191334 -0.02743829 -0.46749247  0.17966774\n  -0.14368533 -0.22070084 -0.31553195  0.12655265  0.49253567 -0.33704514\n   0.2651332  -0.04478692 -0.6421731   0.25787408 -0.23964032  0.07030827\n  -0.34983737  0.10537003 -0.32852215  0.01654786  0.04293211 -0.34609849\n   0.00217689 -0.20317861  0.22401146  0.05551032 -0.18243207  0.12430855\n   0.28927177  0.12773452 -0.06256725  0.2509034   0.38651412  0.31842819\n   0.00386069  0.28961497  0.04469224 -0.1684903  -0.28511967  0.2082034\n   0.10932323  0.11873427 -0.08570699 -0.11188763  0.28101179  0.11925427\n   0.31964398  0.12961355  0.25315342  0.00587253  0.19553578  0.13218485\n  -0.01225431  0.04292897 -0.15000506  0.3301319  -0.34712304 -0.26056413\n   0.02574821 -0.28684763  0.45440465 -0.09032739  0.10873176  0.01544722\n   0.28900267  0.50864726  0.10974705  0.42642457  0.10760907 -0.45489075\n   0.1326754  -0.10491738 -0.13700149 -0.66691436 -0.2197632   0.28620333\n  -0.12860224  0.0609521   0.43035657 -0.18205235 -0.11059838 -0.24391375\n   0.25720128  0.0228605   0.38297156  0.18941286  0.67505233  0.28790026\n  -0.13617276 -0.085705    0.07484249  0.05427266 -0.35962129 -0.12141543\n  -0.43196374  0.46082506 -0.08436694  0.32561657 -0.12173894  0.06935532\n   0.1178788   0.07685079  0.25763738  0.0323275  -0.16166591 -0.27537948\n   0.01875225  0.0976798  -0.06873886  0.45293378 -0.10298198  0.36566639\n  -0.20346727  0.11853031  0.47121694  0.10905323 -0.45459953  0.43635338\n  -0.02661874 -0.2170683   0.06210578  0.16012664  0.2440237  -0.15065752\n  -0.11813315  0.37528888  0.39786082  0.25453152 -0.33516294 -0.3453673\n   0.16372683 -0.25393303 -0.18243154  0.23095003  0.27600715 -0.21151953\n   0.26046459  0.19457453  0.28848904  0.60513181 -0.25957815 -0.11981527\n  -0.27853005 -0.45792075  0.40689782  0.27995852  0.25069941  0.04768465\n  -0.38304236  0.49744457 -0.07629085 -0.50574794  0.24459319  0.36278209\n   0.24936433 -0.54850952  0.06234996  0.30790058  0.20838137 -0.24153266\n  -0.05779423 -0.14414401  0.13637944  0.03370988 -0.15155226 -0.173328\n  -0.17081092  0.54106444  0.6394923   0.30871512  0.26272086  0.56338477\n  -0.08323501  0.22370561  0.26433901  0.49642718  0.03416087  0.48716492\n  -0.1733855  -0.12165455 -0.23700188 -0.18271812  0.02031637  0.39568266\n  -0.03263674 -0.58493558  0.25921003  0.44089831 -0.18430052  0.16289136\n   0.17995125  0.35111083  0.05617799 -0.12620927  0.52631706 -0.16777615]\n [-0.11883062 -0.14694583  0.63755242 -0.21006357  0.49668737  0.20373551\n   0.10927123  0.51115569 -0.30443401 -0.23411205  0.04581446 -0.01496578\n   0.16869901 -0.07285297  0.14188947 -0.11479034 -0.46175323 -0.12110448\n   0.08859013 -0.17910866  0.31475348  0.06816246  0.35353549  0.23006489\n   0.58459504  0.63444472 -0.32928364  0.61527252  0.95647254  0.26943741\n  -0.0423819   0.25981658  0.26999494  0.33245986 -0.21662051 -0.2087583\n  -0.30682759  0.01038855 -0.33958016  0.08191255 -0.11053107  0.17009764\n   0.36088917 -0.19612482 -0.27049829 -0.02796468 -0.50986383  0.4542945\n   0.10479346  0.50421208 -0.06651837  0.23236095 -0.01160919  0.19182245\n   0.21664669 -0.0229772  -0.47191179 -0.02743865 -0.46749255  0.17966928\n  -0.14368448 -0.22070164 -0.31553285  0.12655405  0.49253485 -0.33704509\n   0.26513125 -0.04478522 -0.64217164  0.25787389 -0.23964091  0.07030763\n  -0.34983804  0.10536967 -0.32852229  0.01654943  0.04293244 -0.34609748\n   0.00217641 -0.20317787  0.22401237  0.05551014 -0.18243163  0.12430756\n   0.2892731   0.12773396 -0.06256634  0.25090252  0.38651527  0.31842956\n   0.00386112  0.28961439  0.04469231 -0.16849105 -0.28511915  0.20820455\n   0.10932289  0.11873257 -0.08570641 -0.1118865   0.28101148  0.11925551\n   0.3196439   0.12961351  0.25315363  0.00587388  0.19553563  0.13218408\n  -0.01225244  0.04292975 -0.15000394  0.33013212 -0.34712181 -0.2605626\n   0.02574983 -0.28684678  0.45440503 -0.09032669  0.10873196  0.01544702\n   0.28900326  0.50864701  0.10974679  0.42642403  0.1076095  -0.45489052\n   0.1326756  -0.10491682 -0.1370021  -0.66691417 -0.2197628   0.2862025\n  -0.12860239  0.06095268  0.43035691 -0.18205279 -0.11059688 -0.24391238\n   0.25720049  0.02285983  0.38297145  0.18941342  0.67505227  0.28790163\n  -0.13617353 -0.08570526  0.07484272  0.05427276 -0.35962133 -0.12141586\n  -0.4319635   0.46082469 -0.08436813  0.32561723 -0.12173821  0.06935447\n   0.11787848  0.07685021  0.25763796  0.03232907 -0.16166604 -0.27537894\n   0.01875115  0.09768016 -0.06873829  0.45293404 -0.10298177  0.36566587\n  -0.20346547  0.11852929  0.4712172   0.109054   -0.45459955  0.43635327\n  -0.02661813 -0.21706784  0.06210662  0.16012839  0.24402255 -0.1506581\n  -0.11813262  0.37528877  0.3978608   0.25453136 -0.33516263 -0.34536646\n   0.1637264  -0.25393337 -0.18243204  0.23095161  0.27600677 -0.21151973\n   0.2604644   0.19457589  0.28848954  0.60513246 -0.259577   -0.1198144\n  -0.27853006 -0.45791887  0.40689751  0.27995763  0.25069916  0.04768403\n  -0.38304288  0.49744339 -0.07629074 -0.50574836  0.24459192  0.36278261\n   0.24936319 -0.54851078  0.06235102  0.30789968  0.20838257 -0.24153214\n  -0.05779362 -0.14414406  0.13637859  0.03371133 -0.15155349 -0.17332805\n  -0.17081055  0.54106374  0.63949192  0.30871488  0.26272071  0.56338493\n  -0.08323554  0.22370599  0.2643387   0.49642847  0.03416028  0.48716403\n  -0.17338549 -0.12165526 -0.23700155 -0.18271778  0.02031679  0.39568173\n  -0.03263605 -0.58493552  0.25921028  0.44089783 -0.18429983  0.16289017\n   0.17995123  0.35111115  0.05617802 -0.12621002  0.52631687 -0.1677765 ]]\n\nINPUT index_weights:\n[0.9  0.15 0.05]\n\nINPUT scale:\n1e-05\n\nOUTPUT x_values:\n[0.86692136 0.11669268 0.01638596]\n\nEXPECTED OUTPUT FOR x_values:\n[0.86731656 0.11624638 0.01643706]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "\n",
    "def optimize_portfolio(returns, index_weights, scale=.00001):\n",
    "    \"\"\"\n",
    "    Create a function that takes the return series of a set of stocks, the index weights,\n",
    "    and scaling factor. The function will minimize a combination of the portfolio variance\n",
    "    and the distance of its weights from the index weights.  \n",
    "    The optimization will be constrained to be long only, and the weights should sum to one.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : numpy.ndarray\n",
    "        2D array containing stock return series in each row.\n",
    "        \n",
    "    index_weights : numpy.ndarray\n",
    "        1D numpy array containing weights of the index.\n",
    "        \n",
    "    scale : float\n",
    "        The scaling factor applied to the distance between portfolio and index weights\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        A numpy ndarray containing the weights of the stocks in the optimized portfolio\n",
    "    \"\"\"\n",
    "    # TODO: Use cvxpy to determine the weights on the assets\n",
    "    # that minimizes the combination of portfolio variance and distance from index weights\n",
    "    \n",
    "    # number of stocks m is number of rows of returns, and also number of index weights\n",
    "    m = returns.shape[0]\n",
    "    \n",
    "    # covariance matrix of returns\n",
    "    cov = np.cov(returns)\n",
    "    \n",
    "    # x variables (to be found with optimization)\n",
    "    x = cvx.Variable(m)\n",
    "    \n",
    "    #portfolio variance, in quadratic form\n",
    "    portfolio_variance = cvx.quad_form(x,cov)\n",
    "    \n",
    "    # euclidean distance (L2 norm) between portfolio and index weights\n",
    "    distance_to_index = cvx.norm(x-index_weights)\n",
    "    \n",
    "    #objective function\n",
    "    objective = cvx.Minimize(scale * distance_to_index)\n",
    "    \n",
    "    #constraints\n",
    "    constraints = [x >= 0, sum(x) == 1]\n",
    "\n",
    "    #use cvxpy to solve the objective\n",
    "    \n",
    "    #retrieve the weights of the optimized portfolio\n",
    "    #x_values\n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    \n",
    "    problem.solve()\n",
    "    \n",
    "    x_values = x.value\n",
    "    \n",
    "    return x_values\n",
    "\n",
    "quiz_tests_advanced.test_optimize_portfolio(optimize_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimized weights are [0.86692136 0.11669268 0.01638596], which sum to 1.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test with a 3 simulated stock return series\"\"\"\n",
    "days_per_year = 252\n",
    "years = 3\n",
    "total_days = days_per_year * years\n",
    "\n",
    "return_market = np.random.normal(loc=0.05, scale=0.3, size=days_per_year)\n",
    "return_1 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_2 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_3 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "returns = np.array([return_1, return_2, return_3])\n",
    "\n",
    "\"\"\"simulate index weights\"\"\"\n",
    "index_weights = np.array([0.9,0.15,0.05])\n",
    "\n",
    "\"\"\"try out your optimization function\"\"\"\n",
    "x_values = optimize_portfolio(returns, index_weights, scale=.00001)\n",
    "\n",
    "print(f\"The optimized weights are {x_values}, which sum to {sum(x_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're feeling stuck, you can check out the solution [here](m3l4_cvxpy_advanced_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
